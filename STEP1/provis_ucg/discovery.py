# -----------------------------------------------------------------------------
# module: discovery.py
#
# Purpose:
#   Produce a canonical, deterministic, audited list of source files to parse
#   for Step 1 (UCG) of the Provis OSigDetector. This is the gatekeeper for
#   correctness, security, and reproducibility before AST/CFG/DFG work begins.
#
# Responsibilities:
#   - Deterministic traversal (sorted) under a repo root
#   - Enforce symlink policy (no dir symlinks; file symlinks only within root)
#   - Apply allow/deny globs and vendor/minified/generated skip heuristics
#   - Compute content hashes (blob_sha256) and guess language (py/js/ts)
#   - Emit anomalies for every skip (no silent drops) + coverage tallies
#
# Inputs:
#   - repo_path (str | Path)
#   - optional allow_globs / deny_globs
#
# Outputs:
#   - files: List[DiscoveredFile] with abs/rel path, language, size, is_symlink, blob_sha256
#   - anomalies: List[Anomaly] (type, severity, reason_detail)
#   - tallies: Dict[str, int] (files_seen, supported, skipped_* …)
#
# Guarantees:
#   - Reproducible membership & order on the same tree/commit
#   - Zero silent failures (every exclusion is tallied and explained)
#   - Safety against path escape and oversized/problematic inputs
# -----------------------------------------------------------------------------

from __future__ import annotations

import fnmatch
import os
import stat
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

from .config import (
    DEFAULT_ALLOW_GLOBS,
    DEFAULT_DENY_GLOBS,
    DEFAULT_VENDOR_DIRS,
    MAX_FILE_BYTES,
)
from .hashing import sha256_file_chunked
from .models import Anomaly, AnomalyType, DiscoveredFile, Language, Severity


# ---------- Internal constants ------------------------------------------------

# Filenames that strongly imply minified/bundled JS
_MIN_JS_SUFFIXES = (".min.js", ".bundle.js", ".min.jsx")

# Byte markers near file headers that strongly imply generated code
_GENERATED_MARKERS = (
    b"@generated",
    b"@auto-generated",
    b"autogenerated",
    b"codegen",
    b"do not edit",
)

# Supported source file extensions → Language mapping
_SUPPORTED_EXTS: Dict[str, Language] = {
    ".py": Language.PYTHON,
    ".js": Language.JAVASCRIPT,
    ".jsx": Language.JAVASCRIPT,
    ".ts": Language.TYPESCRIPT,
    ".tsx": Language.TYPESCRIPT,
}


# ---------- Options & result types -------------------------------------------

@dataclass(frozen=True)
class DiscoveryOptions:
    """
    Controls discovery behavior.

    - include_vendor/minified/generated: when False (default), those files are skipped but audited.
      When True, they are included in results (still flagged by anomalies for transparency).
    - allow_globs / deny_globs: glob filters applied to repo-relative paths.
    - max_file_bytes: hard limit per file; oversize files are audited and skipped.
    - compute_hash: compute blob_sha256 content address (True by default).
    """
    include_vendor: bool = False
    include_minified: bool = False
    include_generated: bool = False
    allow_globs: Optional[Iterable[str]] = None
    deny_globs: Optional[Iterable[str]] = None
    max_file_bytes: int = MAX_FILE_BYTES
    compute_hash: bool = True


@dataclass
class DiscoveryResult:
    files: List[DiscoveredFile]
    anomalies: List[Anomaly]
    tallies: Dict[str, int]


# ---------- Public API --------------------------------------------------------

def discover_files(
    repo_path: str | Path,
    *,
    options: Optional[DiscoveryOptions] = None,
) -> DiscoveryResult:
    """
    Deterministic, secure file discovery for Step 1 (UCG).

    Walks the repository (sorted), enforces symlink policy, applies skip heuristics
    (vendor/minified/generated) with "skip but audit" semantics, guesses language,
    enforces maximum file size, and (optionally) computes content hashes to produce
    a canonical list of DiscoveredFile entries for downstream parsing.

    Returns:
        DiscoveryResult(files, anomalies, tallies)
    Raises:
        ValueError: if repo_path does not exist or is not a directory
    """
    opts = options or DiscoveryOptions()

    root = Path(repo_path).resolve()
    if not root.exists() or not root.is_dir():
        raise ValueError(f"repo_path '{repo_path}' does not exist or is not a directory")

    allow_globs = tuple(opts.allow_globs or DEFAULT_ALLOW_GLOBS)
    deny_globs = tuple(opts.deny_globs or DEFAULT_DENY_GLOBS)

    files: List[DiscoveredFile] = []
    anomalies: List[Anomaly] = []
    tallies: Dict[str, int] = {
        "dirs_seen": 0,
        "files_seen": 0,
        "supported": 0,
        "skipped_vendor": 0,
        "skipped_minified": 0,
        "skipped_generated": 0,
        "skipped_deny_glob": 0,
        "skipped_not_allowed": 0,
        "skipped_unsupported": 0,
        "unreadable": 0,
        "symlink_traversed": 0,
        "symlink_out_of_root": 0,
        "oversize": 0,
        "parse_candidates": 0,  # synonym for supported
    }

    def _on_walk_error(err: OSError):
        # Capture directory-level errors deterministically
        anomalies.append(
            Anomaly(
                path=getattr(err, 'filename', str(root)),
                blob_sha256=None,
                typ=AnomalyType.PERMISSION_DENIED,
                severity=Severity.ERROR,
                reason_detail=f"os.walk error: {err.__class__.__name__}",
            )
        )

    # Deterministic traversal: os.walk with sorted dirnames/filenames
    for current_dir, dirnames, filenames in os.walk(root, followlinks=False, onerror=_on_walk_error):
        cur = Path(current_dir)
        tallies["dirs_seen"] += 1

        # In-place sort to guarantee consistent walk order across runs
        dirnames.sort()
        filenames.sort()

        for name in filenames:
            tallies["files_seen"] += 1
            p = cur / name

            # lstat to inspect symlink without dereferencing
            try:
                st = p.lstat()
            except (FileNotFoundError, PermissionError) as exc:
                tallies["unreadable"] += 1
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.PERMISSION_DENIED,
                        severity=Severity.ERROR,
                        reason_detail=f"Stat failed: {exc.__class__.__name__}",
                    )
                )
                continue

            # Skip directories that appear in filenames list (rare)
            if stat.S_ISDIR(st.st_mode):
                continue

            # Symlink handling: we never follow directory symlinks in walk;
            # for file symlinks, allow only if real path remains under root.
            is_symlink = stat.S_ISLNK(st.st_mode)
            if is_symlink:
                try:
                    real = p.resolve()
                except Exception:
                    # If resolve fails (broken link), treat as out-of-root for safety
                    tallies["symlink_out_of_root"] += 1
                    anomalies.append(
                        Anomaly(
                            path=str(p),
                            blob_sha256=None,
                            typ=AnomalyType.SYMLINK_OUT_OF_ROOT,
                            severity=Severity.ERROR,
                            reason_detail="Broken symlink or resolve() failed",
                        )
                    )
                    continue

                if not _within_root(real, root):
                    tallies["symlink_out_of_root"] += 1
                    anomalies.append(
                        Anomaly(
                            path=str(p),
                            blob_sha256=None,
                            typ=AnomalyType.SYMLINK_OUT_OF_ROOT,
                            severity=Severity.ERROR,
                            reason_detail=f"Real path {real} escapes repo root {root}",
                        )
                    )
                    continue
                else:
                    tallies["symlink_traversed"] += 1
                    # Audit traversed symlinks as INFO so it shows up in reports
                    anomalies.append(
                        Anomaly(
                            path=str(p),
                            blob_sha256=None,
                            typ=AnomalyType.SYMLINK_TRAVERSED,
                            severity=Severity.INFO,
                            reason_detail=f"File symlink resolved to {real}",
                        )
                    )

            # Repo-relative path for globbing
            rel = str(p.relative_to(root))

            # Deny/allow globs
            if deny_globs and _match_any_glob(rel, deny_globs):
                tallies["skipped_deny_glob"] += 1
                continue
            if allow_globs and not _match_any_glob(rel, allow_globs):
                tallies["skipped_not_allowed"] += 1
                continue

            # Language support
            lang = _guess_language(p)
            if lang is None:
                tallies["skipped_unsupported"] += 1
                continue

            # Vendor/minified/generated detection
            is_vendor = _is_vendor_path(p, root)
            is_minified = _maybe_minified_js(p)
            is_generated = _maybe_generated(p)

            # Size guard
            size = st.st_size
            if size > opts.max_file_bytes:
                tallies["oversize"] += 1
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.FILE_TOO_LARGE,
                        severity=Severity.ERROR,
                        reason_detail=f"size={size} > max={opts.max_file_bytes}",
                    )
                )
                continue

            # Skip-but-audit policy (unless inclusions are requested)
            if is_vendor and not opts.include_vendor:
                tallies["skipped_vendor"] += 1
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.VENDORED_CODE,
                        severity=Severity.INFO,
                        reason_detail="Vendor directory match",
                    )
                )
                continue

            if is_minified and not opts.include_minified:
                tallies["skipped_minified"] += 1
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.MINIFIED_JS,
                        severity=Severity.WARN,
                        reason_detail="Minified JS heuristic",
                    )
                )
                continue

            if is_generated and not opts.include_generated:
                tallies["skipped_generated"] += 1
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.GENERATED_CODE,
                        severity=Severity.INFO,
                        reason_detail="Generated marker near file header",
                    )
                )
                continue

            # If included vendor/minified/generated, still audit their presence
            if is_vendor and opts.include_vendor:
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.VENDORED_CODE,
                        severity=Severity.INFO,
                        reason_detail="Included by option: vendor directory match",
                    )
                )
            if is_minified and opts.include_minified:
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.MINIFIED_JS,
                        severity=Severity.WARN,
                        reason_detail="Included by option: minified JS heuristic",
                    )
                )
            if is_generated and opts.include_generated:
                anomalies.append(
                    Anomaly(
                        path=str(p),
                        blob_sha256=None,
                        typ=AnomalyType.GENERATED_CODE,
                        severity=Severity.INFO,
                        reason_detail="Included by option: generated marker near header",
                    )
                )

            # Content address (optional, True by default)
            blob_sha = sha256_file_chunked(p) if opts.compute_hash else ""

            files.append(
                DiscoveredFile(
                    abs_path=str(p),
                    rel_path=rel,
                    language=lang,
                    blob_sha256=blob_sha,
                    size_bytes=size,
                    is_symlink=is_symlink,
                )
            )
            tallies["supported"] += 1
            tallies["parse_candidates"] += 1

    # Deterministic order of returned files (relative path then blob)
    files.sort(key=lambda f: (f.rel_path, f.blob_sha256))

    return DiscoveryResult(files=files, anomalies=anomalies, tallies=tallies)


# ---------- Helpers -----------------------------------------------------------

def _guess_language(path: Path) -> Optional[Language]:
    return _SUPPORTED_EXTS.get(path.suffix.lower())


def _within_root(target: Path, root: Path) -> bool:
    try:
        target.relative_to(root)
        return True
    except Exception:
        return False


def _match_any_glob(relpath: str, patterns: Iterable[str]) -> bool:
    return any(fnmatch.fnmatch(relpath, pat) for pat in patterns)


def _is_vendor_path(path: Path, repo_root: Path) -> bool:
    """True if any component under repo_root matches a known vendor directory."""
    try:
        parts = path.relative_to(repo_root).parts
    except ValueError:
        # Should not happen if caller normalized paths under root
        return False
    return any(part in DEFAULT_VENDOR_DIRS for part in parts)


def _maybe_minified_js(path: Path) -> bool:
    """Heuristics for minified/bundled JS; cheap and safe."""
    suffix = path.suffix.lower()
    if suffix not in {".js", ".jsx"}:
        return False
    name = path.name.lower()
    if name.endswith(_MIN_JS_SUFFIXES):
        return True
    # Lightweight line-length heuristic on a bounded sample
    try:
        with path.open("rb") as f:
            sample = f.read(200_000)  # 200KB
        if not sample:
            return False
        line_count = sample.count(b"\n") or 1
        avg_len = len(sample) / line_count
        return avg_len > 240.0
    except Exception:
        # If unreadable, do not classify as minified (another guard would catch)
        return False


def _maybe_generated(path: Path) -> bool:
    """Look for common generated-file markers in the first 16KB."""
    try:
        with path.open("rb") as f:
            head = f.read(16_384)
        head_lower = head.lower()
        return any(marker in head_lower for marker in _GENERATED_MARKERS)
    except Exception:
        return False
